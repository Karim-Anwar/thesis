{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_rgcn_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5nugQ2QL2nY",
        "outputId": "2ed7d514-7efd-4547-a5d8-ffe7c782cb5a"
      },
      "source": [
        "!pip install torch-geometric -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch\n",
        "!pip install rdflib\n",
        "!pip install memory_profiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/61/b3f23832120c404673f6759008312ffe8269524a29bf6116d9980e44517b/torch_geometric-1.7.2.tar.gz (222kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-cp37-none-any.whl size=388143 sha256=e349cf15723a09020b34debcc7515cb94aa6711a97bf0c8e503515066122026a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/66/5b/ad17ef7f04b7c425dc6930daac160c3747231b0d65f9ac7972\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.7.2\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926kB)\n",
            "\u001b[K     |████████████████████████████████| 931kB 7.2MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 8.6MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 8.1MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.7\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.10-cp37-cp37m-linux_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.10\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (5.0.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib) (1.15.0)\n",
            "Collecting memory_profiler\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp37-none-any.whl size=30188 sha256=4a2a4884b3c8fbad803bd004db3b0486b8684175541832de0411b33e493c9b98\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpEPtOUX_w88"
      },
      "source": [
        "%load_ext memory_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y99fgyVQ3JC8",
        "outputId": "1ccb10ae-a78a-4ab2-c0b7-ac210a73c25e"
      },
      "source": [
        "import torch \n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zQofBGDL4mE"
      },
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Entities\n",
        "from torch_geometric.utils import k_hop_subgraph\n",
        "from torch_geometric.nn import RGCNConv, FastRGCNConv\n",
        "from __future__ import print_function, division\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from torch import save\n",
        "from torch import load\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB0k6fkYJw_a"
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXDdiwPvMFgx",
        "outputId": "db3820a5-2f96-4cbe-f1cb-201e2f7e7426"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEEsTGwfgnR_"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/rdf stuff/return_vals/bgs/raw/rbgs.csv')\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.8\n",
        "\n",
        "train = df[msk].drop(columns= ['split'])\n",
        "test = df[~msk].drop(columns= ['split'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWOaKDXfg1aW"
      },
      "source": [
        "train.to_csv('/content/drive/MyDrive/rdf stuff/return_vals/bgs/raw/bgs_train.csv')\n",
        "test.to_csv('/content/drive/MyDrive/rdf stuff/return_vals/bgs/raw/bgs_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUV88DM7g9hd"
      },
      "source": [
        "from typing import Optional, Callable, List\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "from collections import Counter\n",
        "\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
        "                                  extract_tar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOahvUrFhAuC"
      },
      "source": [
        "class MyOwnDataSet(InMemoryDataset):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        root (string): Root directory where the dataset should be saved.\n",
        "        name (string): The name of the dataset (:obj:`\"AIFB\"`,\n",
        "            :obj:`\"MUTAG\"`, :obj:`\"BGS\"`, :obj:`\"AM\"`).\n",
        "        transform (callable, optional): A function/transform that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "            version. The data object will be transformed before every access.\n",
        "            (default: :obj:`None`)\n",
        "        pre_transform (callable, optional): A function/transform that takes in\n",
        "            an :obj:`torch_geometric.data.Data` object and returns a\n",
        "            transformed version. The data object will be transformed before\n",
        "            being saved to disk. (default: :obj:`None`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self) -> str:\n",
        "        return osp.join(self.root, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_dir(self) -> str:\n",
        "        return osp.join(self.root, 'processed')\n",
        "\n",
        "    @property\n",
        "    def num_relations(self) -> str:\n",
        "        return self.data.edge_type.max().item() + 1\n",
        "\n",
        "    @property\n",
        "    def num_classes(self) -> str:\n",
        "        return self.data.train_y.max().item() + 1\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [\n",
        "            'bgs_summarized.nt',\n",
        "            'bgs.csv',\n",
        "            'bgs_train.csv',\n",
        "            'bgs_test.csv',\n",
        "        ]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> str:\n",
        "        return 'data.pt'\n",
        "\n",
        "    # def download(self):\n",
        "    #     path = download_url( '/content/return_vals', self.root)\n",
        "\n",
        "    def process(self):\n",
        "        import rdflib as rdf\n",
        "\n",
        "        graph_file, task_file, train_file, test_file = self.raw_paths\n",
        "\n",
        "        g = rdf.Graph()\n",
        "        with open(graph_file, 'rb') as f:\n",
        "            g.parse(file=f, format='nt')\n",
        "\n",
        "        freq_ = Counter(g.predicates())\n",
        "\n",
        "        def freq(rel):\n",
        "            return freq_[rel] if rel in freq_ else 0\n",
        "\n",
        "        relations = sorted(set(g.predicates()), key=lambda rel: -freq(rel))\n",
        "        subjects = set(g.subjects())\n",
        "        objects = set(g.objects())\n",
        "        nodes = list(subjects.union(objects))\n",
        "\n",
        "        relations_dict = {rel: i for i, rel in enumerate(list(relations))}\n",
        "        nodes_dict = {node: i for i, node in enumerate(nodes)}\n",
        "\n",
        "        edge_list = []\n",
        "        for s, p, o in g.triples((None, None, None)):\n",
        "            src, dst, rel = nodes_dict[s], nodes_dict[o], relations_dict[p]\n",
        "            edge_list.append([src, dst, 2 * rel])\n",
        "            edge_list.append([dst, src, 2 * rel + 1])\n",
        "\n",
        "        edge_list = sorted(edge_list, key=lambda x: (x[0], x[1], x[2]))\n",
        "        edge = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "        edge_index, edge_type = edge[:2], edge[2]\n",
        "\n",
        "        labels_df = pd.read_csv(task_file)\n",
        "        labels_set = set(labels_df['object'].values.tolist())\n",
        "        labels_dict = {lab: i for i, lab in enumerate(list(labels_set))}\n",
        "        nodes_dict = {np.unicode(key): val for key, val in nodes_dict.items()}\n",
        "\n",
        "        train_labels_df = pd.read_csv(train_file)\n",
        "        train_indices, train_labels = [], []\n",
        "        for nod, lab in zip(train_labels_df['subject'].values,\n",
        "                            train_labels_df['object'].values):\n",
        "            train_indices.append(nodes_dict[nod])\n",
        "            train_labels.append(labels_dict[lab])\n",
        "\n",
        "        train_idx = torch.tensor(train_indices, dtype=torch.long)\n",
        "        train_y = torch.tensor(train_labels, dtype=torch.long)\n",
        "\n",
        "        test_labels_df = pd.read_csv(test_file)\n",
        "        test_indices, test_labels = [], []\n",
        "        for nod, lab in zip(test_labels_df['subject'].values,\n",
        "                            test_labels_df['object'].values):\n",
        "            test_indices.append(nodes_dict[nod])\n",
        "            test_labels.append(labels_dict[lab])\n",
        "\n",
        "        test_idx = torch.tensor(test_indices, dtype=torch.long)\n",
        "        test_y = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "        data = Data(edge_index=edge_index)\n",
        "        data.edge_type = edge_type\n",
        "        data.train_idx = train_idx\n",
        "        data.train_y = train_y\n",
        "        data.test_idx = test_idx\n",
        "        data.test_y = test_y\n",
        "        data.num_nodes = edge_index.max().item() + 1\n",
        "\n",
        "        data, slices = self.collate([data])\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "    # def __repr__(self) -> str:\n",
        "    #     return f'{self.name.upper()}{self.__class__.__name__}()'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Q-CUavMSLj",
        "outputId": "3ea819b4-0572-4a13-b214-65c485c4b9b2"
      },
      "source": [
        "dataset = MyOwnDataSet('/content/drive/MyDrive/rdf stuff/return_vals/bgs')\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "# test_10 = []\n",
        "# for i in range(10):\n",
        "node_idx = torch.cat([data.train_idx, data.test_idx], dim=0)\n",
        "node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(node_idx, 2, data.edge_index, relabel_nodes=True)\n",
        "\n",
        "data.num_nodes = node_idx.size(0)\n",
        "data.edge_index = edge_index\n",
        "data.edge_type = data.edge_type[edge_mask]\n",
        "data.train_idx = mapping[:data.train_idx.size(0)]\n",
        "data.test_idx = mapping[data.train_idx.size(0):]\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = RGCNConv(data.num_nodes, 16, dataset.num_relations,\n",
        "                            num_bases=None)\n",
        "    self.conv2 = RGCNConv(16, dataset.num_classes, dataset.num_relations,\n",
        "                            num_bases=None)\n",
        "\n",
        "  def forward(self, edge_index, edge_type):\n",
        "    x = F.relu(self.conv1(None, edge_index, edge_type))\n",
        "    x = self.conv2(x, edge_index, edge_type)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda')\n",
        "# device = torch.device('cpu') if args.dataset == 'AM' else device\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
        "\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data.edge_index, data.edge_type)\n",
        "  loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "  model.eval()\n",
        "  pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
        "  train_acc = pred[data.train_idx].eq(data.train_y).to(torch.float).mean()\n",
        "  test_acc = pred[data.test_idx].eq(data.test_y).to(torch.float).mean()\n",
        "  return train_acc.item(), test_acc.item()\n",
        "\n",
        "# print(device)\n",
        "tests = []\n",
        "train_start = datetime.datetime.now()\n",
        "for epoch in range(1, 51):\n",
        "  start = datetime.datetime.now()\n",
        "  loss = train()\n",
        "  train_acc, test_acc = test()\n",
        "  end = datetime.datetime.now()\n",
        "  time =end - start\n",
        "  print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Test_acc: {test_acc:.4f}, Time: {str(time)}')\n",
        "  tests.append(test_acc)\n",
        "train_end = datetime.datetime.now()\n",
        "train_time = train_end - train_start\n",
        "print('\\n Training: ' + str(train_time))\n",
        "  # test_10.append(np.mean(tests))\n",
        "  # print(test_10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01, Loss: 2.4690, Test_acc: 0.0000, Time: 0:00:00.362326\n",
            "Epoch: 02, Loss: 19.4369, Test_acc: 0.3333, Time: 0:00:00.165364\n",
            "Epoch: 03, Loss: 1.6610, Test_acc: 0.6667, Time: 0:00:00.172155\n",
            "Epoch: 04, Loss: 1.7373, Test_acc: 0.6667, Time: 0:00:00.164965\n",
            "Epoch: 05, Loss: 2.7835, Test_acc: 0.6667, Time: 0:00:00.173559\n",
            "Epoch: 06, Loss: 3.4771, Test_acc: 0.6667, Time: 0:00:00.176199\n",
            "Epoch: 07, Loss: 3.8644, Test_acc: 0.6667, Time: 0:00:00.170045\n",
            "Epoch: 08, Loss: 3.9824, Test_acc: 0.6667, Time: 0:00:00.166554\n",
            "Epoch: 09, Loss: 3.8898, Test_acc: 0.6667, Time: 0:00:00.171596\n",
            "Epoch: 10, Loss: 3.6385, Test_acc: 0.6667, Time: 0:00:00.171951\n",
            "Epoch: 11, Loss: 3.2687, Test_acc: 0.6667, Time: 0:00:00.165902\n",
            "Epoch: 12, Loss: 2.9806, Test_acc: 0.6667, Time: 0:00:00.169907\n",
            "Epoch: 13, Loss: 2.6460, Test_acc: 0.6667, Time: 0:00:00.167521\n",
            "Epoch: 14, Loss: 2.2646, Test_acc: 0.6667, Time: 0:00:00.161827\n",
            "Epoch: 15, Loss: 1.8680, Test_acc: 0.6667, Time: 0:00:00.171419\n",
            "Epoch: 16, Loss: 1.5081, Test_acc: 0.6667, Time: 0:00:00.166215\n",
            "Epoch: 17, Loss: 1.1506, Test_acc: 0.6667, Time: 0:00:00.171137\n",
            "Epoch: 18, Loss: 0.8411, Test_acc: 0.6667, Time: 0:00:00.165547\n",
            "Epoch: 19, Loss: 0.6886, Test_acc: 0.6667, Time: 0:00:00.165540\n",
            "Epoch: 20, Loss: 0.5657, Test_acc: 0.6667, Time: 0:00:00.164152\n",
            "Epoch: 21, Loss: 0.5069, Test_acc: 0.6667, Time: 0:00:00.171854\n",
            "Epoch: 22, Loss: 0.5425, Test_acc: 0.6667, Time: 0:00:00.162188\n",
            "Epoch: 23, Loss: 0.6320, Test_acc: 0.6667, Time: 0:00:00.168450\n",
            "Epoch: 24, Loss: 0.6887, Test_acc: 0.6667, Time: 0:00:00.178037\n",
            "Epoch: 25, Loss: 0.4746, Test_acc: 0.6667, Time: 0:00:00.172468\n",
            "Epoch: 26, Loss: 0.4374, Test_acc: 0.6667, Time: 0:00:00.166530\n",
            "Epoch: 27, Loss: 0.4155, Test_acc: 0.6667, Time: 0:00:00.174449\n",
            "Epoch: 28, Loss: 0.4914, Test_acc: 0.6667, Time: 0:00:00.170163\n",
            "Epoch: 29, Loss: 0.4676, Test_acc: 0.6667, Time: 0:00:00.169042\n",
            "Epoch: 30, Loss: 0.5824, Test_acc: 0.6667, Time: 0:00:00.166575\n",
            "Epoch: 31, Loss: 0.5971, Test_acc: 0.6667, Time: 0:00:00.174441\n",
            "Epoch: 32, Loss: 0.6204, Test_acc: 0.6667, Time: 0:00:00.163335\n",
            "Epoch: 33, Loss: 0.5285, Test_acc: 0.6667, Time: 0:00:00.172377\n",
            "Epoch: 34, Loss: 0.4470, Test_acc: 0.6667, Time: 0:00:00.169097\n",
            "Epoch: 35, Loss: 0.3775, Test_acc: 0.6667, Time: 0:00:00.173063\n",
            "Epoch: 36, Loss: 0.4893, Test_acc: 0.6667, Time: 0:00:00.169448\n",
            "Epoch: 37, Loss: 0.4168, Test_acc: 0.6667, Time: 0:00:00.172254\n",
            "Epoch: 38, Loss: 0.4118, Test_acc: 0.6667, Time: 0:00:00.167297\n",
            "Epoch: 39, Loss: 0.4315, Test_acc: 0.6667, Time: 0:00:00.171721\n",
            "Epoch: 40, Loss: 0.4232, Test_acc: 0.6667, Time: 0:00:00.164665\n",
            "Epoch: 41, Loss: 0.3964, Test_acc: 0.6667, Time: 0:00:00.170042\n",
            "Epoch: 42, Loss: 0.3741, Test_acc: 0.6667, Time: 0:00:00.170030\n",
            "Epoch: 43, Loss: 0.3705, Test_acc: 0.6667, Time: 0:00:00.168738\n",
            "Epoch: 44, Loss: 0.3859, Test_acc: 0.6667, Time: 0:00:00.167687\n",
            "Epoch: 45, Loss: 0.3992, Test_acc: 0.6667, Time: 0:00:00.171642\n",
            "Epoch: 46, Loss: 0.3967, Test_acc: 0.6667, Time: 0:00:00.175660\n",
            "Epoch: 47, Loss: 0.3833, Test_acc: 0.6667, Time: 0:00:00.171467\n",
            "Epoch: 48, Loss: 0.3715, Test_acc: 0.6667, Time: 0:00:00.169586\n",
            "Epoch: 49, Loss: 0.3692, Test_acc: 0.6667, Time: 0:00:00.171455\n",
            "Epoch: 50, Loss: 0.3747, Test_acc: 0.6667, Time: 0:00:00.166296\n",
            "\n",
            " Training: 0:00:08.675991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6O7bS7T0_rc",
        "outputId": "78665d69-67c4-49d2-f749-f23ea5931249"
      },
      "source": [
        "np.mean(tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6466666859388351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Gdm9SKtOUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d71a05-6f5e-4533-f506-7d9d978dd707"
      },
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight \t torch.Size([78, 4, 16])\n",
            "conv1.root \t torch.Size([4, 16])\n",
            "conv1.bias \t torch.Size([16])\n",
            "conv2.weight \t torch.Size([78, 16, 4])\n",
            "conv2.root \t torch.Size([16, 4])\n",
            "conv2.bias \t torch.Size([4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GspEtEEDA1-o",
        "outputId": "5399fe69-8880-4484-bc07-bb6e9c45716f"
      },
      "source": [
        "dataset = Entities('/temp/data', 'BGS')\n",
        "data = dataset[0]\n",
        "\n",
        "# BGS and AM graphs are too big to process them in a full-batch fashion.\n",
        "# Since our model does only make use of a rather small receptive field, we\n",
        "# filter the graph to only contain the nodes that are at most 2-hop neighbors\n",
        "# away from any training/test node.\n",
        "\n",
        "\n",
        "# test_10 = []\n",
        "# for i in range(10):\n",
        "node_idx = torch.cat([data.train_idx, data.test_idx], dim=0)\n",
        "node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(node_idx, 2, data.edge_index, relabel_nodes=True)\n",
        "\n",
        "data.num_nodes = node_idx.size(0)\n",
        "data.edge_index = edge_index\n",
        "data.edge_type = data.edge_type[edge_mask]\n",
        "data.train_idx = mapping[:data.train_idx.size(0)]\n",
        "data.test_idx = mapping[data.train_idx.size(0):]\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = RGCNConv(data.num_nodes, 16, dataset.num_relations,\n",
        "                            num_bases=None)\n",
        "    self.conv2 = RGCNConv(16, dataset.num_classes, dataset.num_relations,\n",
        "                            num_bases=None)\n",
        "\n",
        "  def forward(self, edge_index, edge_type):\n",
        "    x = F.relu(self.conv1(None, edge_index, edge_type))\n",
        "    x = self.conv2(x, edge_index, edge_type)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu') if args.dataset == 'AM' else device\n",
        "model2, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01, weight_decay=0.0005)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://data.dgl.ai/dataset/bgs.tgz\n",
            "Extracting /temp/data/bgs.tgz\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^PRS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^PRS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^PRS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^PRS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^SSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^SSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^~VIS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^PRS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^SSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+#^RSR does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^~VIS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^*SSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^PYSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^~VIS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^~VIS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^~VIS does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^*SSD does not look like a valid URI, trying to serialize this will break.\n",
            "http://data.bgs.ac.uk/id/EarthMaterialClass/RockName/+^*SSD does not look like a valid URI, trying to serialize this will break.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxlG9IdbOPmS"
      },
      "source": [
        "dicti1 = model.conv1.state_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUuFqUioodoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99237bc6-3881-48e5-b4da-9e361be9234b"
      },
      "source": [
        "for param in model2.conv1.parameters():\n",
        "  print(param.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([206, 86145, 16])\n",
            "torch.Size([86145, 16])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aRs3oqIOZfa"
      },
      "source": [
        "out_w = F.pad(dicti1['weight'], (0, 0 , 43070, 43071 , 64, 64 ) ,\"constant\", 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMGUbMTlbWxZ"
      },
      "source": [
        "out_r = F.pad(dicti1['root'], (0, 0 , 43070 , 43071) ,\"constant\", 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx_k25zbb2ID"
      },
      "source": [
        "dicti1['weight'] =out_w\n",
        "dicti1['root'] = out_r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3tCeT-MEJqs"
      },
      "source": [
        "def train():\n",
        "  model2.train()\n",
        "  optimizer.zero_grad()\n",
        "  out = model2(data.edge_index, data.edge_type)\n",
        "  loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "  model2.conv1.load_state_dict(dicti1)\n",
        "  model2.eval()\n",
        "  pred = model2(data.edge_index, data.edge_type).argmax(dim=-1)\n",
        "  train_acc = pred[data.train_idx].eq(data.train_y).to(torch.float).mean()\n",
        "  test_acc = pred[data.test_idx].eq(data.test_y).to(torch.float).mean()\n",
        "  return train_acc.item(), test_acc.item()\n",
        "\n",
        "# print(device)\n",
        "\n",
        "tests = []\n",
        "train_start = datetime.datetime.now()\n",
        "for epoch in range(1, 51):\n",
        "  start = datetime.datetime.now()\n",
        "  loss = train()\n",
        "  train_acc, test_acc = test()\n",
        "  end = datetime.datetime.now()\n",
        "  time =end - start\n",
        "  print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Test_acc: {test_acc:.4f}, Time: {str(time)}')\n",
        "  tests.append(test_acc)\n",
        "train_end = datetime.datetime.now()\n",
        "train_time = train_end - train_start\n",
        "print('\\n Training: ' + str(train_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7BEOOAcyR-G"
      },
      "source": [
        "np.mean(tests)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}